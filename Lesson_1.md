# 简介
1. 大模型从专用模型向通用大模型发展，书生浦语大模型成为研究和工业应用的热点。
2. 书生浦语大模型的开源历程，包括不同尺寸和类型的模型，如7b和20b，以及不同模型的特点和应用场景。
3. 书生浦语的全链条开源体系涵盖了数据、预训练、微调、部署、评测和应用等环节，为开发者提供了丰富的工具和资源。

# 1.大模型成为发展通用人工智能的重要途径
一个模型来应对多种任务和多种模态，去解决多种跨模态任务。通用大模型是通往通用人工智能的一个就关键的途径。

# 2.书生浦语大模型
## 2.1书生浦语大模型的开源历程
2023年6月份，第一次发布
2023年7月份，**千亿参数的大模型进行了全面的升级**-支持了8k语境，26种语言，**全面开源，免费商用**7b开源模型和全链条的工具体系
2023年8月份，**书生·万卷1.0**——多模态的预训练语料库；**升级版对话模型**——开源的智能体的框架支持；**123b千亿参数模型**
2023年9月份，增强版20B开源模型，升级开源工具链
2024年1月份，InternLM2正式开源

## 2.2InternLM2 的体系
轻量级7b和重量级20b都各包含三个模型：
InternLM2-Base
高质量和具有很强可塑性的模型基座，是进行深度领域适配的高质量起点
InternLM2：多个能力方向强化
InternLM2-Chat
在Base基础上，经过SFT和RLHF，面向对话交互进行了优化，有很好的指令理解、共情聊天和调用工具等能力

## 2.3 回归语言建模的本质
关键点：**高质量语料**，让模型能够学会就更好的建模能力
### 新一代的数据清洗过滤技术
多维度的数据价值评估
高质量语料驱动的数据富集
数据的补齐

## 2.4 书生浦语2.0的亮点
1. 具备超长的上下文的能力，支持了20万token上的一个长度，也就是200k它可以实现比较完美的大海捞针的测试
2. 综合性能也得到了全面提升。包括像推理数学代码等等
3. 优秀的对话和创作体验，像指令遵循的能力，然后结构化创作能力都是非常不错
4. 工具调用的能力整体的升级，可以去做可靠的支持，工具多人调用，能够去搭建复杂的智能体
5. 突出的数据能力和使用的数据分析的功能，强化了它的内生计算能力，通过加入代码解释器，在特定评测集上，可以达到和GP4相仿的水平

### 应用举例
ai助手
充满人文关怀的对话
复杂这种数学题的运算和求解

## 2.5 模型到应用典型流程
1. 模型的选型，是模型评测过程
   社区各个不同的开源模型，在一些经典的评测集上，或者大规模的榜单上，整体效果，选其中一个，或几个在业务场景里考虑
2. 考虑业务场景是否复杂
   是比较复杂业务场景：我们就可能去需要去对模型进行微调，使其具备一些业务场景的相关的一些知识
   1）算力足够。全参数的微调
   2）算力有限。部分参数微调，比如Lora微调模型
3. 评估模型是否需要和环境去做交互
   在业务系统里面，或实际应用里面，是否有这种外部的API或者说外部一些工具，需要模型去做交互
   1）如果需要的话，我们需要去进一步构建智能体
   2）如果不需要，那就可以啊就直接去考虑测试模型性能
3. 上线之前进行模型评测
   在实际的场景里面，或者或者说我们实际的这种叫预期的一些领域里面，然后对它做进进一步的评测。
4. 模型部署和上线

# 3 书生浦语全链条开源开放体系
## 3.1 数据
书生万卷1.0：多模态的数据集，总数据量其实达到了两个tb，并里面包括有文本数据，有图像文本的数据，有视频数据，
书生万卷CC：它包括了从2013年到2023年的互联网的公开内容，它是基于CC这样的一个数据，做了非常精细的清洗，并就安全上面也做了处理。
大家都可以在open data lab这样的平台，相当于是实验室的数据平台上来去获取到包括这边的数据集，以及说还有很多其他的一些社区的开源数据集。

## 3.2 预训练
具备高可扩展性，就支持了从8卡到千卡级的一个训练，千卡级别加速效率达92%
能达到50%加速，兼容主流的一些技术生态
能够开箱即用，支持多种不同规格的语言模型

## 3.3 微调-X-tuner微调框架
1. 增量续训
  类似于训练的方式，让模型学到一些新的知识，比如某个垂类领域的知识。
  那这边的训练数据可能是比如说像书籍、文章、代码等等

2. 有监督的微调，主要是让模型学会理解各种指令来去进行对话，或者我们也可以通过有监督微调方式去注入少量领域知识。那这边的训练数据通常来讲是高质量的这种对话或者问答的数据。
  1）全量参数的微调，也就是说我们所模型所有的参数都是放开训练的
  2）部分参数的微调，比如说Lora，固定模型的绝大部分参数，然后通过放开或者引入少量的参数，然后这样能能够去降低整体的一个微调的成本。

3. X-tuner
   1）适配多种生态。
   不同的一些微调策略和算法，能够去覆盖各类的sft的场景；适配不同的一些开源生态；自动的优化加速优化加速，让开发者可以不用去关注这些复杂的一些显存优化和计算加速的细节
   2）适配不同的硬件。能够覆盖比如说像Nvidia20系列以上的所有显卡，最低其实只需要8G的显存就可以去微调7b的模型。

## 3.4 评测_open compass2.0司南大模型评测体系
1. 中立全面的性能榜单，大语言模型的这种榜单和多模态模型评测的榜单
2. compass kit——大模型评测权重工具链
3. compasshub——高质量评测基准社区

### 评测结论
从语言知识推理、数学代码、智能体这多个方面来去进行评测。最高的是Gpt-4
1）整体能力有较大提升空间
2）复杂的推理场景短板
3）偏理科的能力的一些啊分数和模型的尺寸有比较强的一个关联性。
语言和知识这样的一类偏文科的维度上，中轻量级的模型的商业模型差距比较小。
但是再比如说像数学推理偏理科的维度上，性能和尺寸就呈现比较强的相关性。
4）模型主客观性能需综合参考

## 3.5 模型部署
模型上线应用里面的最后一环
1）模型的轻量化，比如4bit权重的量化，然后8bit K/v
2）推理引擎，比如pytorch
3）服务模块，比如兼容open AI-server的接口
4）访问接口，比如说像直接的Python接口，

## 3.6 智能体
### 轻量级的智能体框架Legent
1）支持多种类型智能体，比如说像ReAct，ReWoo
2）灵活支持各种大语言模型，包括GPt-3.5和GP4，有很多一些内置工具，可以直接使用。
3）简单易拓展，支持丰富的工具

### 多模态智能体工具箱——Agent-Lego。
提供了大量的这种跟视觉多模态相关的领域的一些前沿的算法功能
stable diffusion，然后像一些语音的模型，包括像这种Sam这一类分割的模型，在agent lego里面其实都做了支持。







